{"cells":[{"cell_type":"markdown","metadata":{"id":"ijser6G2GmII"},"source":["https://github.com/lukemelas/PyTorch-Pretrained-ViT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":81541,"status":"ok","timestamp":1716882658783,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"},"user_tz":-540},"id":"Bde5h0mvGHIb","outputId":"201078c3-7b7d-4002-b8a1-df6634f892a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch_pretrained_vit\n","  Downloading pytorch-pretrained-vit-0.0.7.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_vit) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->pytorch_pretrained_vit)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->pytorch_pretrained_vit)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_pretrained_vit) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_pretrained_vit) (1.3.0)\n","Building wheels for collected packages: pytorch_pretrained_vit\n","  Building wheel for pytorch_pretrained_vit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytorch_pretrained_vit: filename=pytorch_pretrained_vit-0.0.7-py3-none-any.whl size=11114 sha256=e59f2999ff39d87688c06ad1831b6fb9e933f7af1dd14526ec64b2515df2d8aa\n","  Stored in directory: /root/.cache/pip/wheels/2d/46/ad/12007be9d377d0fbf27ef75b6e47ed92832ab6b70dbf004b6f\n","Successfully built pytorch_pretrained_vit\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch_pretrained_vit\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pytorch_pretrained_vit-0.0.7\n"]}],"source":["pip install pytorch_pretrained_vit"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13014,"status":"ok","timestamp":1716882674903,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"},"user_tz":-540},"id":"gcB5ftUVGa-7","outputId":"9392cf80-5bc7-4680-cdee-27f52ab49050"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/B_16_imagenet1k.pth\" to /root/.cache/torch/hub/checkpoints/B_16_imagenet1k.pth\n","100%|██████████| 331M/331M [00:02<00:00, 162MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights.\n"]},{"data":{"text/plain":["ViT(\n","  (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","  (positional_embedding): PositionalEmbedding1D()\n","  (transformer): Transformer(\n","    (blocks): ModuleList(\n","      (0-11): 12 x Block(\n","        (attn): MultiHeadedSelfAttention(\n","          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n","          (drop): Dropout(p=0.1, inplace=False)\n","        )\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (pwff): PositionWiseFeedForward(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  (fc): Linear(in_features=768, out_features=1000, bias=True)\n",")"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","from PIL import Image\n","import torch\n","from torchvision import transforms\n","\n","# Load ViT\n","from pytorch_pretrained_vit import ViT\n","model = ViT('B_16_imagenet1k', pretrained=True)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16585,"status":"ok","timestamp":1716882694232,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"},"user_tz":-540},"id":"yaJWHEPhBj6Z","outputId":"5507e079-a6e0-4a83-e1f4-fe2309774e4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HjDJtr0qK94z"},"outputs":[],"source":["from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n","\n","# Transformations 설정\n","transform = Compose([\n","    Resize((224, 224)),\n","    ToTensor(),\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# ImageFolder를 사용하여 데이터셋 로드\n","dataset = ImageFolder('/content/drive/My Drive/Project/train', transform=transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MmV-hNerDtEc"},"outputs":[],"source":["from torch.utils.data import Subset\n","import numpy as np\n","\n","indices = np.random.choice(len(dataset), 3000, replace=False)\n","subset_dataset = Subset(dataset, indices)\n","\n","# DataLoader 설정\n","batch_size = 32\n","data_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716881393044,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"},"user_tz":-540},"id":"IRhOq2X6Gv4i","outputId":"9727296d-e59d-486b-eb8c-5458a35ed762"},"outputs":[{"name":"stdout","output_type":"stream","text":["ViT(\n","  (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","  (positional_embedding): PositionalEmbedding1D()\n","  (transformer): Transformer(\n","    (blocks): ModuleList(\n","      (0-11): 12 x Block(\n","        (attn): MultiHeadedSelfAttention(\n","          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n","          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n","          (drop): Dropout(p=0.1, inplace=False)\n","        )\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (pwff): PositionWiseFeedForward(\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  (fc): Linear(in_features=768, out_features=1000, bias=True)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tvx1sH8tFN1k"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","num_classes = 2\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","\n","# loss func & optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCXYj1XjG6Qs"},"outputs":[],"source":["val_transform = Compose([\n","    Resize((384, 384)),\n","    ToTensor(),\n","    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_dataset = ImageFolder('/content/drive/My Drive/Project/valid', transform=val_transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hel9Q9PzH7EY"},"outputs":[],"source":["val_indices = np.random.choice(len(dataset), 900, replace=False)\n","subset_val_dataset = Subset(val_dataset, val_indices)\n","\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MuC8KLqpIhRb"},"outputs":[],"source":["def validate(model, data_loader, criterion):\n","    model.eval()\n","    total_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in data_loader:\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    avg_loss = total_loss / len(data_loader)\n","    accuracy = 100 * correct / total\n","    return avg_loss, accuracy\n","\n","#train\n","epochs = 10\n","for epoch in range(epochs):\n","    model.train()\n","    for images, labels in data_loader:\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'Epoch {epoch+1}, Training Loss: {loss.item()}')\n","\n","    #valid\n","    val_loss, val_accuracy = validate(model, val_loader, criterion)\n","    print(f'Epoch {epoch+1}, Validation Loss: {val_loss}, Accuracy: {val_accuracy}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qffpDyzBItZ5"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyM977smMiLAsQbjCFd7vOfS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}