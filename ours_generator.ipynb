{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEDNIjMYB-xP"
   },
   "source": [
    "pre-trained: https://github.com/CompVis/stable-diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMxyhGmswcR7"
   },
   "source": [
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/image_variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83269,
     "status": "ok",
     "timestamp": 1717093433521,
     "user": {
      "displayName": "Yebin",
      "userId": "18281467583627149322"
     },
     "user_tz": -540
    },
    "id": "6DXnRz6ysZbX",
    "outputId": "44f3dfb3-0a06-4e60-9fac-0ce0cd2a4db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
      "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
      "Collecting diffusers\n",
      "  Downloading diffusers-0.28.0-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.23.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.25.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.2.2)\n",
      "Installing collected packages: diffusers\n",
      "Successfully installed diffusers-0.28.0\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install accelerate\n",
    "!pip install diffusers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15142,
     "status": "ok",
     "timestamp": 1717093448659,
     "user": {
      "displayName": "Yebin",
      "userId": "18281467583627149322"
     },
     "user_tz": -540
    },
    "id": "WTlfGSKnEBFq",
    "outputId": "543a07e2-0e69-482e-95d7-afd3dc009777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhD4FfFWr2Q7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "# 이미지가 있는 디렉토리 경로 설정\n",
    "directory_path = '/content/drive/MyDrive/ArtificialIntelligence/Project/train/real'\n",
    "\n",
    "# 디렉토리 내의 모든 파일 목록 가져오기\n",
    "all_files = []\n",
    "for f in os.listdir(directory_path):\n",
    "  full_path = os.path.join(directory_path, f)\n",
    "  if os.path.isfile(full_path):\n",
    "    all_files.append(full_path)\n",
    "\n",
    "# 파일 목록에서 무작위로 선택\n",
    "random.seed(42)\n",
    "\n",
    "if len(all_files) > 10:\n",
    "    selected_files = random.sample(all_files, 10)\n",
    "else:\n",
    "    selected_files = all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1717093789684,
     "user": {
      "displayName": "Yebin",
      "userId": "18281467583627149322"
     },
     "user_tz": -540
    },
    "id": "D84VF-j-vWS4",
    "outputId": "926c490f-0147-4e92-be74-fd514dd70443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/22480.jpg', '/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/62372.jpg', '/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/69496.jpg', '/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/10875.jpg', '/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/45903.jpg', '/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/49131.jpg', '/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/51815.jpg', '/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/59690.jpg', '/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/10630.jpg', '/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/61888.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(selected_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1717093790002,
     "user": {
      "displayName": "Yebin",
      "userId": "18281467583627149322"
     },
     "user_tz": -540
    },
    "id": "LwkQozmv7cAc",
    "outputId": "869dad58-f02c-4aec-fb51-799b7c899e70"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/ArtificialIntelligence/Project/train/real/22480.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0MWaFAafqEP"
   },
   "source": [
    "##### 생성된 결과가 train image와 너무 안 비슷하다. self-evolving의 개념을 활용해서 원본 이미지의 스타일과 최대한 비슷하면서도 prompt대로 따라갈 수는 없을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W92eHghaiptI"
   },
   "source": [
    "##### VGG-19 말고 Inception으로도 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10866,
     "status": "ok",
     "timestamp": 1717093802143,
     "user": {
      "displayName": "Yebin",
      "userId": "18281467583627149322"
     },
     "user_tz": -540
    },
    "id": "0zvBkwyaf6qY",
    "outputId": "fae99e99-5dd9-4594-8d74-e707974afd2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [00:03<00:00, 144MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# VGG19 네트워크 로드\n",
    "class VGGFeatures(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGFeatures, self).__init__()\n",
    "        vgg_pretrained_features = models.vgg19(pretrained=True).features\n",
    "\n",
    "        self.layers = {\n",
    "            '0': 'conv1_1',\n",
    "            '5': 'conv2_1',\n",
    "            '10': 'conv3_1',\n",
    "            '19': 'conv4_1',\n",
    "            '28': 'conv5_1'\n",
    "        }\n",
    "\n",
    "        self.features = nn.ModuleDict()\n",
    "        for idx, layer_name in self.layers.items():\n",
    "            self.features[layer_name] = vgg_pretrained_features[int(idx)]\n",
    "\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        results = {}\n",
    "        for layer_name, layer in self.features.items():\n",
    "            x = layer(x)\n",
    "            results[layer_name] = x\n",
    "        return results\n",
    "\n",
    "\n",
    "# 인스턴스화\n",
    "vgg = VGGFeatures().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1504,
     "status": "ok",
     "timestamp": 1717085841810,
     "user": {
      "displayName": "Yebin",
      "userId": "18281467583627149322"
     },
     "user_tz": -540
    },
    "id": "kcE2Lp04nZQ1",
    "outputId": "6bf7ee4d-b0ed-4bb5-c504-4ffc83f7ea3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|██████████| 104M/104M [00:01<00:00, 102MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class InceptionFeatures(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionFeatures, self).__init__()\n",
    "        inception_pretrained_features = models.inception_v3(pretrained=True)\n",
    "\n",
    "        # Inception v3는 aux_logits와 transform_input 등을 포함하므로 이를 조정\n",
    "        self.inception = inception_pretrained_features\n",
    "        self.inception.aux_logits = False\n",
    "        self.inception.transform_input = False\n",
    "\n",
    "        self.layers = {\n",
    "            'Mixed_5b': 'mixed_5b',\n",
    "            'Mixed_6a': 'mixed_6a',\n",
    "            'Mixed_6b': 'mixed_6b',\n",
    "            'Mixed_6c': 'mixed_6c',\n",
    "            'Mixed_7a': 'mixed_7a'\n",
    "        }\n",
    "\n",
    "        self.features = nn.ModuleDict()\n",
    "        for layer_name in self.layers.keys():\n",
    "            self.features[layer_name] = getattr(self.inception, layer_name)\n",
    "\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        results = {}\n",
    "        # inception 모델의 preprocess 필요\n",
    "        x = self.inception.Conv2d_1a_3x3(x)\n",
    "        x = self.inception.Conv2d_2a_3x3(x)\n",
    "        x = self.inception.Conv2d_2b_3x3(x)\n",
    "        x = self.inception.maxpool1(x)\n",
    "        x = self.inception.Conv2d_3b_1x1(x)\n",
    "        x = self.inception.Conv2d_4a_3x3(x)\n",
    "        x = self.inception.maxpool2(x)\n",
    "\n",
    "        # 정의된 층에서 특징 추출\n",
    "        for layer_name, layer in self.features.items():\n",
    "            x = layer(x)\n",
    "            results[layer_name] = x\n",
    "\n",
    "        return results\n",
    "\n",
    "# 인스턴스화\n",
    "Inception = InceptionFeatures().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7sKPPsn0nebS"
   },
   "outputs": [],
   "source": [
    "# 이미지 전처리\n",
    "def preprocess_image(image_path):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return preprocess(image) .unsqueeze(0)\n",
    "\n",
    "def preprocess_image_wo_path(image):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return preprocess(image).unsqueeze(0)\n",
    "\n",
    "# 스타일 특징 비교\n",
    "def gram_matrix(input):\n",
    "    a, b, c, d = input.size()\n",
    "    features = input.view(a * b, c * d)\n",
    "    G = torch.mm(features, features.t())\n",
    "    return G.div(a * b * c * d)\n",
    "\n",
    "def style_distance(target_features, style_features):\n",
    "    distance = 0\n",
    "    for layer in target_features.keys():\n",
    "        gram_target = gram_matrix(target_features[layer])\n",
    "        gram_style = gram_matrix(style_features[layer])\n",
    "        distance += torch.nn.functional.l1_loss(gram_target, gram_style)\n",
    "    return distance.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732,
     "referenced_widgets": [
      "97b63a02853d43e4aecd66c8b1e7bd94",
      "605171fa15ed4652bbd31fd016821b4d",
      "0b22dd57e03147818f44c284adf2b317",
      "13e1ad32994e41adbf0684cead45a843",
      "cfb1ac56ff504b91bb021ed2a56713a3",
      "72ee8ecd9141483399cb9a62adaef3a8",
      "29f4ed3047a64fcd9a792f375d4cdef2",
      "e2d4b1fdbcfc46d8a701588831beed8f",
      "eb7b5441a70d4d8394cb2ab25f4a603b",
      "ff20f35d1bbd48f4b8020402e26d2ab9",
      "366df6edba0c47b1bcc7b347849d8811",
      "a9b7e95884cc482db671d1b6b010ca98",
      "f86a78b56f5d45d48511f0b00785284c",
      "7402e01a685442c38beb93ac34cd24aa",
      "8ae342b1bda84c3b80cc5845895e1e20",
      "3c8f403998444f5a952b3f3a747fcfb1",
      "436a51e2a3fe4fcba043fa2bf191e140",
      "ee86640d9e5d4f5db2cd9dc0e5559404",
      "19cc5053d5004f86a463bee53315639e",
      "121611da14ce4d45b3e10e7d432c9c05",
      "92a8ae189d7b4b20a06f5cc1de56cdde",
      "f40f4db92dec48bebeb6e8b23af65d54",
      "fa256f86b51f4d0296f6a7136f618ca9",
      "f2660293886741f793ba240a46759f18",
      "afefb0bfd57e48bc8a2a3f8f62711387",
      "70ede1df15f04cf49bdf4d17da88dd2a",
      "2af3cb1dc2fc4ec19135fde6f6651a44",
      "23b7c07c48684b62a8af9175969028db",
      "a822c48666b2475ea4bfcef2635cffd9",
      "0b14fef8c21341c18fcf590cee556741",
      "14b77523af0742cda4327870387f94ff",
      "f7e913be018d4e89a5882cdf60f6a426",
      "799a309e7d754b57aef97fd6a04fe7a3",
      "606a259e31bc4339b36c8659edf987a5",
      "e638cb3c99604c5e8934d5e717757b61",
      "3911cad2d7c1457e9630924b0a870ac0",
      "c131aabe76d04eb19a5b83a377532e79",
      "724f97d01958450287af8965da95cc7d",
      "6ee1e17ecb1b4ae18ec2c7016cc6f86c",
      "cce45170a04a46abae48294e72bc6933",
      "4fc5fefb764242b7bfb4a47c99b192d0",
      "5564e98f70284da1bf9db5ba58dd0a86",
      "1858bb76227d4ecf98523304a7562b6a",
      "13bba47f3d304bddaae58dac72817d38",
      "ee8d291ed5e342549e6706494bd8b5a7",
      "ee46970328ae4962bdcf12a9dacc2ff5",
      "a8900053e7dd44a58ddce64ff66dbc31",
      "8f6106943d794d9798c67f4ebaba84c2",
      "91ba946b4abf4f4abc4ae80cdce39a6e",
      "75682daa17e742d08aad930da9a3b288",
      "20f1c7a25c4f47e8a60e2d284170889b",
      "51ec5e79f3dd406bbccf8af10629470f",
      "3caedbc0176840b18920f85032625d35",
      "61c2ae1753e241fdaea5eea9e963de20",
      "89bbae725bf64da3b071c1e779988cf7",
      "724235386f67496997ee1cd9e89c03c6",
      "bdf8ab5b6c484d779a55e6dfb027a48b",
      "f8b45e39e2a5481c97a7d274e809c3fc",
      "d270b771dfb64e908eb478f619c5d973",
      "3ab8183d8dbf4ba9941c081e1f631f77",
      "21bb4c53a5da4e9b8a6ddf3210f7252d",
      "0269e869e7df499e95ddd9963d5ad1ba",
      "7cdcd12c02ec47edb47ee16f37980694",
      "59ae511a94554160a12d6f137e13e565",
      "9b76cac355124257a7061aa9433652d7",
      "51945e30d6ab46dd9f8e1d2b98082efc",
      "5ca9b7db27e74ca6aabd733891a91b25",
      "6c52981d9c824f8f869dbf19426c3639",
      "bddc58d483a34d06829ceb1b6ac83800",
      "d8e2495b297b48e69c4417b9f6994d2a",
      "453fac5248ba4afaa81ebe6e7cc0a481",
      "3fedf93d2a154b3384b87131b79fadbb",
      "3fae7ce9d3d245cd9530f080e81f816f",
      "5c893a86f5a04c3db04b09282cb143a1",
      "db6e5a2fa97c4f6cba21270ee1fbc427",
      "b1f08606abd24b0f8fd865671c751bc3",
      "2bb4aa7817084b53907dcbfc57f892dc",
      "523dd965837f47dd97d9e62508ded42a",
      "33e70bc93efb4ffaa7cd9ed589510796",
      "6ef5fc9365824db885ff816a8faf1021",
      "2b51ef408c6a4390ba8d9e8582f8bb50",
      "23e16754488e4d3fb28a3ddb9608676b",
      "c84c1eac4d784f26bef1a4e351875489",
      "d0051301da6647169d8cdb476e655103",
      "c708ee58f6c54fd391c43f4e166094e0",
      "abb746a6cf644d7cb86a42154f205313",
      "ed680c8380164514a054d4e256b6ab74",
      "a08b5e8448f941c5a2a4645396a51a3b",
      "70255e736a1e4d1f8eae683c50cb2ee1",
      "197d59cce4b748b1b948acca6b776668",
      "499a437ab0434901a0a2ae53feabb43f",
      "d398b9625ddb4f4fa5af413717551261",
      "9083973dc71c4912a804ac59833e0173",
      "b2a7f06eeaa4453b99e4d79178d2dce5",
      "519e5ca8ec69433093282029ac7ec5a4",
      "54422c740e3c4372b97d5a5ca82eeef7",
      "10e49bdc4d6c42a995038bfaebeb58e4",
      "28c7297cc0a04b219debc078407ef61c",
      "8755abeb37cc403f97a0d474e50c50e1",
      "5747a0e1c7a74eed834c54ca57a7a179",
      "89c320c6018e4e019e09c3fdf1b3bd6e",
      "1c31571695a44f2b840f24b6a3dde9f5",
      "c02a464fe33e49e8ae00b4af9bb8a949",
      "a8a989d48e2c4317abb89dd692c812a7",
      "e352ce677f4a48db808705ee0c20ef05",
      "a8486f8c171e4c04b251d499f3ca86c6",
      "e2b5db28202f495b9a62243716977b00",
      "41608c91824347a6ba640190bcd460fd",
      "4d123504338d469890aa67856e3fe527",
      "327dc97b91db4776bdd508e8a4fea855"
     ]
    },
    "executionInfo": {
     "elapsed": 118198,
     "status": "error",
     "timestamp": 1717094872980,
     "user": {
      "displayName": "Yebin",
      "userId": "18281467583627149322"
     },
     "user_tz": -540
    },
    "id": "OAYR0BaJ8RXo",
    "outputId": "da730452-ced3-4b83-b13c-057ec1163a0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_encoder/model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b63a02853d43e4aecd66c8b1e7bd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b7e95884cc482db671d1b6b010ca98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/284 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa256f86b51f4d0296f6a7136f618ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/595 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606a259e31bc4339b36c8659edf987a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/config.json:   0%|          | 0.00/871 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8d291ed5e342549e6706494bd8b5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "image_encoder/config.json:   0%|          | 0.00/703 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724235386f67496997ee1cd9e89c03c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/518 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca9b7db27e74ca6aabd733891a91b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523dd965837f47dd97d9e62508ded42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.bin:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70255e736a1e4d1f8eae683c50cb2ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.bin:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5747a0e1c7a74eed834c54ca57a7a179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_image_variation.StableDiffusionImageVariationPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "StableDiffusionImageVariationPipeline.__call__() got an unexpected keyword argument 'prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a75a3cf09dbc>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m#print(current_prompt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inference_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguidance_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0;31m# strength: 1에 가까울 수록 원본 이미지에 가깝고, 0에 가까울 수록 prompt에 충실\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# guidance_scale: prompt를 얼마나 엄격하게 따를 것인가 7.5~20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: StableDiffusionImageVariationPipeline.__call__() got an unexpected keyword argument 'prompt'"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionImageVariationPipeline\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "# Stable Diffusion 모델 파이프라인을 초기화.\n",
    "pipe = StableDiffusionImageVariationPipeline.from_pretrained(\n",
    "    \"lambdalabs/sd-image-variations-diffusers\",\n",
    "    revision=\"v2.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker = None,\n",
    ").to(\"cuda\")\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "# Real face 이미지를 로드\n",
    "  input_image_path = selected_files[i]\n",
    "  img = Image.open(input_image_path).convert('RGB')\n",
    "  #img = preprocess_image(input_image_path)\n",
    "\n",
    "  # 이미지 생성\n",
    "  prompt = ['A single portrait of a smiling face of only one person whose gender is opposite to the input image',\n",
    "            'A single portrait of a smiling face of only one person whose race is different to the input image',\n",
    "            'A single portrait of a smiling face of only one person whose age range is different to the input image']\n",
    "\n",
    "  current_prompt = random.choice(prompt)\n",
    "  #print(current_prompt)\n",
    "\n",
    "  generated_image = pipe(prompt = current_prompt, image=img, num_inference_steps=50, strength=0.8, guidance_scale=20).images[0]\n",
    "  # strength: 1에 가까울 수록 원본 이미지에 가깝고, 0에 가까울 수록 prompt에 충실\n",
    "  # guidance_scale: prompt를 얼마나 엄격하게 따를 것인가 7.5~20\n",
    "\n",
    "  target_img = preprocess_image(input_image_path).to('cuda')\n",
    "  gen_img = preprocess_image_wo_path(generated_image).to('cuda')\n",
    "\n",
    "  target_feat = vgg(target_img)\n",
    "  gen_feat = vgg(gen_img)\n",
    "\n",
    "  distance = style_distance(target_feat, gen_feat)\n",
    "\n",
    "  print(f'{i}-th image\\'s Difference(distance): {distance}')\n",
    "\n",
    "  threshold = 0.2\n",
    "\n",
    "  if distance > threshold:\n",
    "    current_prompt += 'being similar to the initial image style'\n",
    "    for j in range(5):\n",
    "      generated_img = pipe(prompt = current_prompt, image = img, num_inference_steps = 50, strength = 0.8, guidance_scale = 20).images[0]\n",
    "\n",
    "      gen_img = preprocess_image_wo_path(generated_img).to('cuda')\n",
    "      gen_feat = vgg(gen_img)\n",
    "      distance = style_distance(target_feat, gen_feat)\n",
    "\n",
    "      if distance <= threshold:\n",
    "          break\n",
    "\n",
    "  path = f'/content/drive/MyDrive/ArtificialIntelligence/Project/GeneratedImages/image{i}.jpg'\n",
    "  generated_img.save(path)\n",
    "\n",
    "print(\"Completed generating images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqGUJMQKSu8_"
   },
   "source": [
    "##### 비슷하게 만들 수 없다면, 처음부터 얼굴 부분만 segmentation해서 변형시킬 수는 없을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AnrJ8GrJIhnw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzm0sPkgHZNf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
