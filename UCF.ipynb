{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wgTKe9k-fR1","executionInfo":{"status":"ok","timestamp":1717821084267,"user_tz":-540,"elapsed":18668,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}},"outputId":"79a6c3e5-a2ec-4806-ab8b-c2ca1b780d41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","project_path = '/content/drive/MyDrive/Project/DeepfakeBench/training'\n","sys.path.append(project_path)"],"metadata":{"id":"bDErdxhp_Awz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install simplejson"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3DgGHjJBd_b","executionInfo":{"status":"ok","timestamp":1717821095960,"user_tz":-540,"elapsed":10854,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}},"outputId":"f8e9f5b1-d69d-421e-b250-917724112b08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting simplejson\n","  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: simplejson\n","Successfully installed simplejson-3.19.2\n"]}]},{"cell_type":"code","source":["pip install fvcore"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7Y-6STeCKbU","executionInfo":{"status":"ok","timestamp":1717821113514,"user_tz":-540,"elapsed":17559,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}},"outputId":"ac96ef3e-8d66-4709-f7fb-1938d96793c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore) (1.25.2)\n","Collecting yacs>=0.1.6 (from fvcore)\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.4)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.4.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (9.4.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\n","Collecting iopath>=0.1.7 (from fvcore)\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (4.12.1)\n","Collecting portalocker (from iopath>=0.1.7->fvcore)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=4a871fea9193428349381861dd1b20d6501e5e9ee860952f5052e3e979c2c0da\n","  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=f0c6da09a342616431d7f18a75833a5040894552650cc39dfd0714932b3cea9c\n","  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n","Successfully built fvcore iopath\n","Installing collected packages: yacs, portalocker, iopath, fvcore\n","Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.8.2 yacs-0.1.8\n"]}]},{"cell_type":"code","source":["pip install efficientnet_pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CN2hPneGH9Jn","outputId":"011bdaa0-6f22-4a27-9901-7edd79de4878","executionInfo":{"status":"ok","timestamp":1717821195056,"user_tz":-540,"elapsed":81558,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting efficientnet_pytorch\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet_pytorch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet_pytorch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet_pytorch\n","  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=5a403168760fb19e2970bd24ab1e6475f10671e9d8846ed741388af53ea39a99\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","Successfully built efficientnet_pytorch\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet_pytorch\n","Successfully installed efficientnet_pytorch-0.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","source":["pip install kornia"],"metadata":{"id":"DueCIjVsIiKU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717821213939,"user_tz":-540,"elapsed":18886,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}},"outputId":"71d24dd2-5278-4263-b60f-8612b974dae0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kornia\n","  Downloading kornia-0.7.2-py2.py3-none-any.whl (825 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kornia-rs>=0.1.0 (from kornia)\n","  Downloading kornia_rs-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (24.0)\n","Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.1->kornia) (12.5.40)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n","Installing collected packages: kornia-rs, kornia\n","Successfully installed kornia-0.7.2 kornia-rs-0.1.3\n"]}]},{"cell_type":"code","source":["pip install timm"],"metadata":{"id":"d1QH0K9rIsro","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717821228437,"user_tz":-540,"elapsed":14519,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}},"outputId":"3e36193c-a36a-4cf5-83ce-0c2533398dcf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timm\n","  Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.5.40)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","Installing collected packages: timm\n","Successfully installed timm-1.0.3\n"]}]},{"cell_type":"code","source":["pip install lmdb"],"metadata":{"id":"f7S_QUV8Kzh1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717821241950,"user_tz":-540,"elapsed":13533,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}},"outputId":"0f989cb0-e6e7-4cb2-8d2c-ce6f263d5784"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lmdb\n","  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lmdb\n","Successfully installed lmdb-1.4.1\n"]}]},{"cell_type":"code","source":["pip install loralib"],"metadata":{"id":"inH4YrU8xqte","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717821255148,"user_tz":-540,"elapsed":13210,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}},"outputId":"4d743fae-a3bf-463a-c0b5-225c40ad666d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting loralib\n","  Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n","Installing collected packages: loralib\n","Successfully installed loralib-0.1.2\n"]}]},{"cell_type":"code","source":["pip install einops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DSphIyN9fD8","executionInfo":{"status":"ok","timestamp":1717821265225,"user_tz":-540,"elapsed":10080,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}},"outputId":"3af1e668-282e-4240-d544-0230d71ff1ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting einops\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.8.0\n"]}]},{"cell_type":"code","source":["# author: Zhiyuan Yan\n","# email: zhiyuanyan@link.cuhk.edu.cn\n","# date: 2023-03-30\n","# description: training code.\n","\n","import os\n","import argparse\n","from os.path import join\n","import cv2\n","import random\n","import datetime\n","import time\n","import yaml\n","from tqdm import tqdm\n","import numpy as np\n","from datetime import timedelta\n","from copy import deepcopy\n","from PIL import Image as pil_image\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.utils.data\n","import torch.optim as optim\n","from torch.utils.data.distributed import DistributedSampler\n","import torch.distributed as dist\n","\n","from optimizor.SAM import SAM\n","from optimizor.LinearLR import LinearDecayLR"],"metadata":{"id":"2BAQIFQt_mXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from trainer.trainer import Trainer\n","from detectors.ucf_detector import *\n","#from detectors import DETECTOR\n","from metrics.utils import parse_metric_for_print\n","from logger import create_logger, RankFilter"],"metadata":{"id":"sh-egvLsIEcX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from dataset import *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"oWfW9WQqJ3Jh","executionInfo":{"status":"error","timestamp":1717658977955,"user_tz":-540,"elapsed":10450,"user":{"displayName":"5기김정현","userId":"05713384309589019705"}},"outputId":"ad8d9822-d57a-4e13-dfdc-b6c2664bf4d0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Unable to open ../preprocessing/dlib_tools/shape_predictor_81_face_landmarks.dat","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-d22282e1c4ec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/Project/DeepfakeBench/training/dataset/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mabstract_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepfakeAbstractBaseDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mff_blend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFFBlendDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfwa_blend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFWABlendDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlrl_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLRLDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpair_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpairDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Project/DeepfakeBench/training/dataset/fwa_blend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mface_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mpredictor_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../preprocessing/dlib_tools/shape_predictor_81_face_landmarks.dat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mface_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Unable to open ../preprocessing/dlib_tools/shape_predictor_81_face_landmarks.dat"]}]},{"cell_type":"code","source":["from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","import random"],"metadata":{"id":"mwOnAY-a5ALL","executionInfo":{"status":"ok","timestamp":1717830416939,"user_tz":-540,"elapsed":344,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["parser = argparse.ArgumentParser(description='Process some paths.')\n","parser.add_argument('--detector_path', type=str,\n","                    default='/content/drive/MyDrive/Project/DeepfakeBench/training/config/detector/ucf.yaml',\n","                    help='path to detector YAML file')\n","parser.add_argument(\"--train_dataset\", nargs=\"+\", default=[\"/content/drive/MyDrive/Project/train\"])\n","parser.add_argument(\"--valid_dataset\", nargs=\"+\", default=[\"/content/drive/MyDrive/Project/valid\"])\n","parser.add_argument(\"--test_dataset\", nargs=\"+\", default=[\"/content/drive/MyDrive/Project/test\"])\n","parser.add_argument('--no-save_ckpt', dest='save_ckpt', action='store_false', default=True)\n","parser.add_argument('--no-save_feat', dest='save_feat', action='store_false', default=True)\n","parser.add_argument(\"--ddp\", action='store_true', default=False)\n","parser.add_argument('--local_rank', type=int, default=0)\n","args, unknown = parser.parse_known_args()\n","#torch.cuda.set_device(args.local_rank)"],"metadata":{"id":"9XQHCa4BPvKD","executionInfo":{"status":"ok","timestamp":1717823429272,"user_tz":-540,"elapsed":325,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["from data_preprocess.preprocess import prepare_train_input, prepare_test_input"],"metadata":{"id":"oFCCfNKXmD4e","executionInfo":{"status":"ok","timestamp":1717821950446,"user_tz":-540,"elapsed":4840,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["from backbones.adm import *"],"metadata":{"id":"pkYFc80RNsME","executionInfo":{"status":"ok","timestamp":1717822787759,"user_tz":-540,"elapsed":3,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class RealFakeDataset(Dataset):\n","    def __init__(self, root_dir, transform=None, config=None, is_train=True, sample_size=500):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.config = config\n","        self.is_train = is_train\n","        self.data = []\n","\n","        if self.is_train:\n","            for label, sub_dir in enumerate(['real', 'fake']):\n","                full_dir = os.path.join(root_dir, sub_dir)\n","                for filename in os.listdir(full_dir):\n","                    file_path = os.path.join(full_dir, filename)\n","                    self.data.append({'image': file_path, 'label': label})\n","\n","            if len(self.data) > sample_size:\n","                self.data = random.sample(self.data, sample_size)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        image = pil_image.open(item['image']).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return {'image': image, 'label': item['label']}\n","\n","def prepare_training_data(config):\n","    transform = transforms.Compose([\n","        transforms.Resize((256, 256)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","\n","    train_dataset = RealFakeDataset(root_dir=config['train_dataset'][0], transform=transform, config=config)\n","    train_data_loader = DataLoader(\n","        dataset=train_dataset,\n","        batch_size=config['train_batchSize'],\n","        shuffle=True,\n","        num_workers=int(config['workers']),\n","        collate_fn=lambda x: tuple(zip(*x))\n","    )\n","\n","    return train_data_loader\n","\n","def prepare_testing_data(config):\n","    transform = transforms.Compose([\n","        transforms.Resize((256, 256)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","\n","    test_data_loaders = {}\n","    for test_name in config['test_dataset']:\n","        test_dataset = RealFakeDataset(root_dir=test_name, transform=transform, config=config, is_train=False)\n","        test_data_loader = DataLoader(\n","            dataset=test_dataset,\n","            batch_size=config['test_batchSize'],\n","            shuffle=False,\n","            num_workers=int(config['workers']),\n","            collate_fn=lambda x: tuple(zip(*x))\n","        )\n","        test_data_loaders[test_name] = test_data_loader\n","\n","    return test_data_loaders"],"metadata":{"id":"EKhejN99h0IM","executionInfo":{"status":"ok","timestamp":1717830426128,"user_tz":-540,"elapsed":616,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["def init_seed(config):\n","    if config['manualSeed'] is None:\n","        config['manualSeed'] = random.randint(1, 10000)\n","    random.seed(config['manualSeed'])\n","    if config['cuda']:\n","        torch.manual_seed(config['manualSeed'])\n","        torch.cuda.manual_seed_all(config['manualSeed'])\n","\n","def choose_optimizer(model, config):\n","    opt_name = config['optimizer']['type']\n","    if opt_name == 'sgd':\n","        optimizer = optim.SGD(\n","            params=model.parameters(),\n","            lr=config['optimizer'][opt_name]['lr'],\n","            momentum=config['optimizer'][opt_name]['momentum'],\n","            weight_decay=config['optimizer'][opt_name]['weight_decay']\n","        )\n","        return optimizer\n","    elif opt_name == 'adam':\n","        optimizer = optim.Adam(\n","            params=model.parameters(),\n","            lr=config['optimizer'][opt_name]['lr'],\n","            weight_decay=config['optimizer'][opt_name]['weight_decay'],\n","            betas=(config['optimizer'][opt_name]['beta1'], config['optimizer'][opt_name]['beta2']),\n","            eps=config['optimizer'][opt_name]['eps'],\n","            amsgrad=config['optimizer'][opt_name]['amsgrad'],\n","        )\n","        return optimizer\n","    elif opt_name == 'sam':\n","        optimizer = SAM(\n","            model.parameters(),\n","            optim.SGD,\n","            lr=config['optimizer'][opt_name]['lr'],\n","            momentum=config['optimizer'][opt_name]['momentum'],\n","        )\n","    else:\n","        raise NotImplementedError('Optimizer {} is not implemented'.format(config['optimizer']))\n","    return optimizer\n","\n","\n","def choose_scheduler(config, optimizer):\n","    if config['lr_scheduler'] is None:\n","        return None\n","    elif config['lr_scheduler'] == 'step':\n","        scheduler = optim.lr_scheduler.StepLR(\n","            optimizer,\n","            step_size=config['lr_step'],\n","            gamma=config['lr_gamma'],\n","        )\n","        return scheduler\n","    elif config['lr_scheduler'] == 'cosine':\n","        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n","            optimizer,\n","            T_max=config['lr_T_max'],\n","            eta_min=config['lr_eta_min'],\n","        )\n","        return scheduler\n","    elif config['lr_scheduler'] == 'linear':\n","        scheduler = LinearDecayLR(\n","            optimizer,\n","            config['nEpochs'],\n","            int(config['nEpochs']/4),\n","        )\n","    else:\n","        raise NotImplementedError('Scheduler {} is not implemented'.format(config['lr_scheduler']))\n","\n","\n","def choose_metric(config):\n","    metric_scoring = config['metric_scoring']\n","    if metric_scoring not in ['eer', 'auc', 'acc', 'ap']:\n","        raise NotImplementedError('metric {} is not implemented'.format(metric_scoring))\n","    return metric_scoring"],"metadata":{"id":"3ZZjx9U2M77N","executionInfo":{"status":"ok","timestamp":1717822540422,"user_tz":-540,"elapsed":351,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def main():\n","    # parse options and load config\n","    with open(args.detector_path, 'r') as f:\n","        config = yaml.safe_load(f)\n","    with open('/content/drive/MyDrive/Project/DeepfakeBench/training/config/train_config.yaml', 'r') as f:\n","        config2 = yaml.safe_load(f)\n","    config.update(config2)\n","    config['local_rank']=args.local_rank\n","    if config['dry_run']:\n","        config['nEpochs'] = 0\n","        config['save_feat']=False\n","    # If arguments are provided, they will overwrite the yaml settings\n","    if args.train_dataset:\n","        config['train_dataset'] = args.train_dataset\n","    if args.test_dataset:\n","        config['test_dataset'] = args.test_dataset\n","    config['save_ckpt'] = args.save_ckpt\n","    config['save_feat'] = args.save_feat\n","    config['ddp']= args.ddp\n","\n","    # create logger\n","    logger_path = config['log_dir']\n","    os.makedirs(logger_path, exist_ok=True)\n","    logger = create_logger(os.path.join(logger_path, 'training.log'))\n","    logger.info('Save log to {}'.format(logger_path))\n","\n","    '''\n","    # print configuration\n","    logger.info(\"--------------- Configuration ---------------\")\n","    params_string = \"Parameters: \\n\"\n","    for key, value in config.items():\n","        params_string += \"{}: {}\".format(key, value) + \"\\n\"\n","    logger.info(params_string)\n","    '''\n","\n","    # init seed\n","    init_seed(config)\n","\n","    # set cudnn benchmark if needed\n","    if config['cudnn']:\n","        cudnn.benchmark = True\n","    if config['ddp']:\n","        # dist.init_process_group(backend='gloo')\n","        dist.init_process_group(\n","            backend='nccl',\n","            timeout=timedelta(minutes=30)\n","        )\n","        logger.addFilter(RankFilter(0))\n","\n","    extra_layers = [ADM_ExtraBlock for _ in range(3)] + [ADM_EndBlock]\n","    model = Artifact_Detection_Module(inplanes=3, extra_layers=extra_layers)\n","\n","    # prepare the training data loader\n","    train_data_loader = prepare_training_data(config)\n","\n","    # prepare the testing data loader\n","    test_data_loaders = prepare_testing_data(config)\n","\n","    '''\n","    # prepare the model (detector)\n","    model_class = DETECTOR[config['model_name']]\n","    model = model_class(config)\n","    '''\n","\n","    # prepare the optimizer\n","    optimizer = choose_optimizer(model, config)\n","\n","    # prepare the scheduler\n","    scheduler = choose_scheduler(config, optimizer)\n","\n","    # prepare the metric\n","    metric_scoring = choose_metric(config)\n","\n","    # prepare the trainer\n","    trainer = Trainer(config, model, optimizer, scheduler, logger, metric_scoring)\n","\n","    # start training\n","    for epoch in range(config['start_epoch'], config['nEpochs'] + 1):\n","        trainer.model.epoch = epoch\n","        best_metric = trainer.train_epoch(\n","                    epoch=epoch,\n","                    train_data_loader=train_data_loader,\n","                    test_data_loaders=test_data_loaders,\n","                )\n","        if best_metric is not None:\n","            logger.info(f\"===> Epoch[{epoch}] end with testing {metric_scoring}: {parse_metric_for_print(best_metric)}!\")\n","    logger.info(\"Stop Training on best Testing metric {}\".format(parse_metric_for_print(best_metric)))\n","    # update\n","    if scheduler is not None:\n","        scheduler.step()\n","\n","    # close the tensorboard writers\n","    for writer in trainer.writers.values():\n","        writer.close()\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":721},"id":"ZKp_HICk-NnU","executionInfo":{"status":"error","timestamp":1717830434509,"user_tz":-540,"elapsed":1496,"user":{"displayName":"­정재희 | 데이터사이언스전공 | 한양대(서울)","userId":"06340913878035256272"}},"outputId":"b974c63a-0a36-4ce9-fe94-3b1d7bb1ebb7"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["[06/08 07:07:12][INFO] root:   25: Save log to /data/home/zhiyuanyan/DeepfakeBench/debug_logs/ucf\n"]},{"output_type":"stream","name":"stderr","text":["2024-06-08 07:07:12,904 - INFO - Save log to /data/home/zhiyuanyan/DeepfakeBench/debug_logs/ucf\n","2024-06-08 07:07:12,904 - INFO - Save log to /data/home/zhiyuanyan/DeepfakeBench/debug_logs/ucf\n","2024-06-08 07:07:12,904 - INFO - Save log to /data/home/zhiyuanyan/DeepfakeBench/debug_logs/ucf\n","2024-06-08 07:07:12,904 - INFO - Save log to /data/home/zhiyuanyan/DeepfakeBench/debug_logs/ucf\n","2024-06-08 07:07:12,904 - INFO - Save log to /data/home/zhiyuanyan/DeepfakeBench/debug_logs/ucf\n","2024-06-08 07:07:12,904 - INFO - Save log to /data/home/zhiyuanyan/DeepfakeBench/debug_logs/ucf\n","2024-06-08 07:07:12,904 - INFO - Save log to /data/home/zhiyuanyan/DeepfakeBench/debug_logs/ucf\n"]},{"output_type":"stream","name":"stdout","text":["[06/08 07:07:14][INFO] root:  220: ===> Epoch[0] start!\n"]},{"output_type":"stream","name":"stderr","text":["2024-06-08 07:07:14,050 - INFO - ===> Epoch[0] start!\n","2024-06-08 07:07:14,050 - INFO - ===> Epoch[0] start!\n","2024-06-08 07:07:14,050 - INFO - ===> Epoch[0] start!\n","2024-06-08 07:07:14,050 - INFO - ===> Epoch[0] start!\n","2024-06-08 07:07:14,050 - INFO - ===> Epoch[0] start!\n","2024-06-08 07:07:14,050 - INFO - ===> Epoch[0] start!\n","2024-06-08 07:07:14,050 - INFO - ===> Epoch[0] start!\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'RealFakeDataset' object has no attribute 'data_dict'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-d64776e5df93>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-57-d64776e5df93>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nEpochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         best_metric = trainer.train_epoch(\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Project/DeepfakeBench/training/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, epoch, train_data_loader, test_data_loaders)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# save the training data_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_data_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# define training recorder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'RealFakeDataset' object has no attribute 'data_dict'"]}]},{"cell_type":"code","source":["def main():\n","    # parse options and load config\n","    with open(args.detector_path, 'r') as f:\n","        config = yaml.safe_load(f)\n","    with open('./training/config/train_config.yaml', 'r') as f:\n","        config2 = yaml.safe_load(f)\n","    config.update(config2)\n","    config['local_rank']=args.local_rank\n","    if config['dry_run']:\n","        config['nEpochs'] = 0\n","        config['save_feat']=False\n","    # If arguments are provided, they will overwrite the yaml settings\n","    if args.train_dataset:\n","        config['train_dataset'] = args.train_dataset\n","    if args.test_dataset:\n","        config['test_dataset'] = args.test_dataset\n","    config['save_ckpt'] = args.save_ckpt\n","    config['save_feat'] = args.save_feat\n","    if config['lmdb']:\n","        config['dataset_json_folder'] = 'preprocessing/dataset_json_v3'\n","    # create logger\n","    logger_path = config['log_dir']\n","    os.makedirs(logger_path, exist_ok=True)\n","    logger = create_logger(os.path.join(logger_path, 'training.log'))\n","    logger.info('Save log to {}'.format(logger_path))\n","    config['ddp']= args.ddp\n","\n","    # print configuration\n","    logger.info(\"--------------- Configuration ---------------\")\n","    params_string = \"Parameters: \\n\"\n","    for key, value in config.items():\n","        params_string += \"{}: {}\".format(key, value) + \"\\n\"\n","    logger.info(params_string)\n","\n","    # init seed\n","    init_seed(config)\n","\n","    # set cudnn benchmark if needed\n","    if config['cudnn']:\n","        cudnn.benchmark = True\n","    if config['ddp']:\n","        # dist.init_process_group(backend='gloo')\n","        dist.init_process_group(\n","            backend='nccl',\n","            timeout=timedelta(minutes=30)\n","        )\n","        logger.addFilter(RankFilter(0))\n","\n","    extra_layers = [ADM_ExtraBlock for _ in range(3)] + [ADM_EndBlock]\n","    model = Artifact_Detection_Module(inplanes=3, extra_layers=extra_layers)\n","\n","    # prepare the training data loader\n","    train_data_loader = prepare_training_data(config)\n","\n","    # prepare the testing data loader\n","    test_data_loaders = prepare_testing_data(config)\n","\n","    '''\n","    # prepare the model (detector)\n","    model_class = DETECTOR[config['model_name']]\n","    model = model_class(config)\n","    '''\n","\n","    # prepare the optimizer\n","    optimizer = choose_optimizer(model, config)\n","\n","    # prepare the scheduler\n","    scheduler = choose_scheduler(config, optimizer)\n","\n","    # prepare the metric\n","    metric_scoring = choose_metric(config)\n","\n","    # prepare the trainer\n","    trainer = Trainer(config, model, optimizer, scheduler, logger, metric_scoring)\n","\n","    # start training\n","    for epoch in range(config['start_epoch'], config['nEpochs'] + 1):\n","        trainer.model.epoch = epoch\n","        best_metric = trainer.train_epoch(\n","                    epoch=epoch,\n","                    train_data_loader=train_data_loader,\n","                    test_data_loaders=test_data_loaders,\n","                )\n","        if best_metric is not None:\n","            logger.info(f\"===> Epoch[{epoch}] end with testing {metric_scoring}: {parse_metric_for_print(best_metric)}!\")\n","    logger.info(\"Stop Training on best Testing metric {}\".format(parse_metric_for_print(best_metric)))\n","    # update\n","    if 'svdd' in config['model_name']:\n","        model.update_R(epoch)\n","    if scheduler is not None:\n","        scheduler.step()\n","\n","    # close the tensorboard writers\n","    for writer in trainer.writers.values():\n","        writer.close()\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"id":"JiJgMN1F-jiv"},"execution_count":null,"outputs":[]}]}